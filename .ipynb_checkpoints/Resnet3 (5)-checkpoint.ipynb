{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5kqQdv2WLcPY",
    "outputId": "87326f02-e1e8-457b-ef3f-a3fd331ddeca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tGL3tu9GLd-8",
    "outputId": "f2bd67bf-d8b6-4358-d399-629f2699623f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "TMAAidaSLegf",
    "outputId": "06aa3081-adc3-4daf-850d-7a0b22e0dc99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "(Reading database ... 110851 files and directories currently installed.)\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
      "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHgdz59FLezl"
   },
   "outputs": [],
   "source": [
    " !mkdir -p drive\n",
    " !google-drive-ocamlfuse drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UJpXkvOGLfA0",
    "outputId": "7130c29c-9402-42e0-9d95-e60ccbb4a50b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ge1O9LsYLfNc",
    "outputId": "33376da0-92ea-47b1-acf5-e57a06c24255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hKoXEspfLfY6",
    "outputId": "4947dc94-0a80-45e5-ac07-00f806eec27c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/图像识别\n"
     ]
    }
   ],
   "source": [
    "cd content/drive/图像识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyw9xiE6Lfke"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IKFYZRYLUu7"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image  #Python的图像处理库\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR8YMOF6RWC2"
   },
   "source": [
    "# 数据处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNlr2T4PRTJp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from shutil import copyfile,rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-4Je8PyIvxL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBXsEJ6NRTHe"
   },
   "outputs": [],
   "source": [
    "#新建路径是为了存放分开的测试集和验证集\n",
    "data_folder = 'data_v1/'#原始图像目录\n",
    "new_data_folder = 'data_v1/分类数据/'#新的文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zC-c6WAk0j7"
   },
   "outputs": [],
   "source": [
    "#提取路径下的所有文件名\n",
    "def data_path(DIR):\n",
    "  data_dir = []\n",
    "  for i in os.listdir(DIR):\n",
    "    path = os.path.join(DIR,i)\n",
    "    data_dir.append(path)\n",
    "  return data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lnf2dY5vl3OY"
   },
   "outputs": [],
   "source": [
    "DIR1 = 'data_v1/no_damage'\n",
    "good_car_dir = data_path(DIR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XklwTSS-mJVP"
   },
   "outputs": [],
   "source": [
    "DIR1 = 'data_v1/other'\n",
    "other_damage_dir = data_path(DIR1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sZhXZuEFIRAX",
    "outputId": "af11a5b3-dab2-4ffa-cdc5-5ce3d0c30d7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_damage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dygxDkQmJe2"
   },
   "outputs": [],
   "source": [
    "DIR1 =  'data_v1/scratch'\n",
    "scrath_dir = data_path(DIR1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lWXCfIdxq12N",
    "outputId": "d6303c9d-9b25-4b1a-98f8-2b3741182059"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = good_car_dir + other_damage_dir + scrath_dir\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sOgxN3fnpsF"
   },
   "outputs": [],
   "source": [
    "#提取数据的标签\n",
    "def Label(data):\n",
    "  labels = []\n",
    "  for i in data:\n",
    "    label = i.split('/')[1:]\n",
    "    labels.append(label)\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wS7dWfyEqMIA"
   },
   "outputs": [],
   "source": [
    "label_total = Label(good_car_dir) + Label(other_damage_dir) + Label(scrath_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hzEMd3XORgTo",
    "outputId": "ab304377-68f0-4c74-d06c-34071cbb9a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_damage', '34.jpg']"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_total[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esg1Am9qtu09"
   },
   "outputs": [],
   "source": [
    "#限定训练集、验证集、测试集的样本数\n",
    "train_size = 800\n",
    "test_size = 280\n",
    "val_size= 154\n",
    "np.random.shuffle(label_total)#随机打乱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "T3ISzcVnc34g",
    "outputId": "20189575-e70d-45c0-c9c9-8fd50ea3d35f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nL-jkIwkuTl_"
   },
   "outputs": [],
   "source": [
    "#新建train、validation、test文件夹并存放相应数量的图片\n",
    "current_i = 0\n",
    "\n",
    "def save_images(current_i,phase,d_size):\n",
    "\n",
    "    if phase == 'train':\n",
    "\n",
    "        dst_folder = new_data_folder+'train/'\n",
    "\n",
    "    elif phase == 'test':\n",
    "\n",
    "        dst_folder = new_data_folder+'test/'\n",
    "\n",
    "    elif phase == 'validation':\n",
    "\n",
    "        dst_folder = new_data_folder+'validation/'\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('phase error')\n",
    "\n",
    "        exit()\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(current_i,current_i+d_size):\n",
    "\n",
    "        r = label_total[i]\n",
    "\n",
    "        img_full_path = data_folder+r[0] + '/' + r[1]\n",
    "\n",
    "        img_class = r[0]\n",
    "\n",
    "        img_new_path = dst_folder+img_class+'/'+r[1]\n",
    "\n",
    "\n",
    "\n",
    "        if not os.path.exists(dst_folder+img_class):\n",
    "\n",
    "            os.makedirs(dst_folder+img_class)\n",
    "\n",
    "        copyfile(img_full_path,img_new_path)\n",
    "\n",
    "        print(img_new_path,' copied')\n",
    "\n",
    "    current_i = i\n",
    "\n",
    "\n",
    "\n",
    "    return current_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5utfuObuZf7"
   },
   "outputs": [],
   "source": [
    "new_i = save_images(current_i=0,phase='train',d_size=train_size)\n",
    "new_i = save_images(current_i=new_i,phase='test',d_size=test_size)\n",
    "new_i = save_images(current_i=new_i,phase='validation',d_size=val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqUlS7WCuZot"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0mwpz8VqMRu"
   },
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-N_AqHl7mj0"
   },
   "source": [
    "# 数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SP89Gzb6Abmm"
   },
   "outputs": [],
   "source": [
    "import argparse,json,sys,glob,time\n",
    "sys.path.append('lib')\n",
    "sys.path.insert(0, r'lib\\tensorflow_gpu')\n",
    "from pdb import set_trace as dd\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dpujdvLAbyr"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "train_data_dir = r'data_v1/分类数据/train' \n",
    "validation_data_dir = r'data_v1/分类数据/validation' \n",
    "test_data_dir = r'data_v1/分类数据/test'\n",
    "\n",
    "nb_train_samples = 800\n",
    "nb_validation_samples = 154\n",
    "nb_epoch = 280\n",
    "nb_classes = 3  # number of target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "LWfBJroh76zB",
    "outputId": "4e7fa498-93fd-44f3-890a-acd5de114f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 794 images belonging to 3 classes.\n",
      "Found 156 images belonging to 3 classes.\n",
      "Found 279 images belonging to 3 classes.\n",
      "start history model\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator( rescale=1./255)#,\n",
    " #       shear_range=0.2,\n",
    " #       zoom_range=0.2,\n",
    " #       horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "print( \"start history model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-6IYx_G--8O"
   },
   "outputs": [],
   "source": [
    "A = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3s-KB6nJMcl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBNmHUT38DlO"
   },
   "source": [
    "###  迁移学习和微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrurFgAI8KsW"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "这里的base_model和model里面的iv3都指向同一个地址\n",
    "'''\n",
    "def setup_to_transfer_learning(model,base_model):#base_model 迁移模型\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "def setup_to_fine_tune(model,base_model):#微调\n",
    "    GAP_LAYER = 17 # max_pooling_2d_2\n",
    "    for layer in base_model.layers[:GAP_LAYER+1]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[GAP_LAYER+1:]:\n",
    "        layer.trainable = True\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "h5TCS5XZ-2i9",
    "outputId": "b893c2f6-7e7f-4d9a-fa9a-ff907c807c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 279 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_data_dir, \n",
    "                                                  target_size=(224, 224),\n",
    "                                                  batch_size=1,class_mode='categorical', \n",
    "                                                  shuffle=False,)\n",
    "labels = (test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTeCFnGp9bNK"
   },
   "outputs": [],
   "source": [
    "# 将矩阵转换成文字\n",
    "def pre(preds):\n",
    "  if preds[0][0]==1 and preds[0][1]==0 and preds[0][2]==0:\n",
    "    return '无剐蹭'\n",
    "  elif preds[0][0]==0 and preds[0][1]==1 and preds[0][2]==0:\n",
    "    return '存在其他损伤'\n",
    "  elif preds[0][0]==0 and preds[0][1]==0 and preds[0][2]==1:\n",
    "    return '存在剐蹭'\n",
    "  else:\n",
    "    return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45ifY5Kat-ly"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owtjquvh8NKn"
   },
   "source": [
    "# InceptionV3、ResNet50、VGG16、CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nq7u04qdB_Q1"
   },
   "source": [
    "##  InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP0-iDRz8_0o"
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.inception_v3 import decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "AQGqZTkDBtjl",
    "outputId": "2a2525b7-d5e5-49c6-e8fb-30e93a2f674c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized), i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers: layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbfQa2aKF-NK"
   },
   "outputs": [],
   "source": [
    "setup_to_transfer_learning(model,base_model)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath = 'data_v1/0122_inception_best_weights.hdf5',verbose=1\n",
    "                              ,save_best_only =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "sDlDlaiETJn8",
    "outputId": "26573581-db07-4042-d3d2-73d44dfc79fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.0827 - acc: 0.9669 - val_loss: 2.5331 - val_acc: 0.6383\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0965 - acc: 0.9574 - val_loss: 1.8363 - val_acc: 0.6223\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.1708 - acc: 0.9365 - val_loss: 0.7942 - val_acc: 0.7660\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.1323 - acc: 0.9493 - val_loss: 0.8541 - val_acc: 0.7609\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.1192 - acc: 0.9561 - val_loss: 1.3665 - val_acc: 0.7128\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.0644 - acc: 0.9775 - val_loss: 1.4279 - val_acc: 0.7553\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.1154 - acc: 0.9578 - val_loss: 1.2994 - val_acc: 0.7128\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0583 - acc: 0.9837 - val_loss: 1.1887 - val_acc: 0.7234\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.1067 - acc: 0.9621 - val_loss: 1.3076 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.1098 - acc: 0.9546 - val_loss: 1.1511 - val_acc: 0.6915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_tl = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=12,#12\n",
    "                    class_weight='auto'\n",
    "                    )\n",
    "model.save('data_v1/car_iv3_tl.h5')#存放训练好的权重\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTtbnMcgV47a"
   },
   "outputs": [],
   "source": [
    "setup_to_fine_tune(model,base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "OIMPCi1LW_BU",
    "outputId": "e417f9aa-70ac-4826-8a2b-3cd4cb390443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "800/800 [==============================] - 479s 598ms/step - loss: 0.0775 - acc: 0.9771 - val_loss: 0.5258 - val_acc: 0.8125\n",
      "Epoch 2/2\n",
      "800/800 [==============================] - 462s 577ms/step - loss: 0.0256 - acc: 0.9935 - val_loss: 2.4321 - val_acc: 0.8125\n"
     ]
    }
   ],
   "source": [
    "history_ft = model.fit_generator(generator=train_generator,\n",
    "                                 steps_per_epoch=800,\n",
    "                                 epochs=2,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 validation_steps=1,\n",
    "                                 class_weight='auto')\n",
    "model.save('0121/car_iv3_ft.h5')#存放训练好的权重\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JlU4litwex5y",
    "outputId": "2fa7a924-8203-4dc3-ced2-69673165ed46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8653846155756559\n"
     ]
    }
   ],
   "source": [
    "scoreSeg = model.evaluate_generator(validation_generator, 400)\n",
    "print(\"Accuracy = \",scoreSeg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVJvd7-5yplD"
   },
   "outputs": [],
   "source": [
    "model.load_weights('0121/car_iv3_ft.h5')#调用训练好权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1GqSYmStwpK"
   },
   "outputs": [],
   "source": [
    "image_path = \"data_v1/分类数据/test/scratch/125.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flCTrfY8twyW"
   },
   "outputs": [],
   "source": [
    "\n",
    "img = image.load_img(image_path,target_size=(224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPotB6gdtxGc"
   },
   "outputs": [],
   "source": [
    "preds = np.trunc(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "qkRbL3ix11-n",
    "outputId": "f6008c09-e054-4ffd-da17-95217f2b89b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经由模型判断，图片类别为： 存在剐蹭\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f09c5c84898>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAADGCAYAAAB4kKTQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"经由模型判断，图片类别为：\",pre(preds))\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F8X42PSmkh7N",
    "outputId": "715ec24a-3ca0-4fe0-bf45-653bc9bc3abf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 23s 82ms/step\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "test_generator.reset()\n",
    "pred = model.predict_generator(test_generator,279, verbose=1)#生成step个数据，下面是对应的标签\n",
    "\n",
    "predicted_class_indices = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "U4wjiqg2NVEP",
    "outputId": "9cc88176-48ad-410a-ddf1-8fa7a9033e6c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-332ca9c4513b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mB1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_class_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_class_indices' is not defined"
     ]
    }
   ],
   "source": [
    "A1=list(A)\n",
    "B1=list(predicted_class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "mGS6RUCi_koC",
    "outputId": "b80f8a9b-17f5-4a2e-8322-f53297a4f12d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    good_car       0.99      0.84      0.91       112\n",
      "     scratch       0.89      0.32      0.47        25\n",
      "       other       0.81      0.99      0.89       142\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       279\n",
      "   macro avg       0.89      0.72      0.76       279\n",
      "weighted avg       0.89      0.87      0.86       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#求precision、recall、f1-score\n",
    "  \n",
    "print(classification_report(A1,B1, target_names=['good_car',  'scratch','other']))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G2zfaK6oED1n"
   },
   "source": [
    "## restnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34NQ9WVfxXWK"
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from pdb import set_trace as dd\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import h5py\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "q7c44RFiCPmZ",
    "outputId": "217a8b34-ccf3-435e-93cd-2e6e0733b7b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(224, 224, 3))    \n",
    "base_model = ResNet50(input_tensor=input_tensor,include_top=False,weights='imagenet')    \n",
    "#base_model = ResNet50(input_tensor=input_tensor,include_top=False,weights=None)    \n",
    "get_resnet50_output = K.function([base_model.layers[0].input, K.learning_phase()],                              \n",
    "                                 [base_model.layers[-1].output])\n",
    "input_tensor = Input(shape=(224, 224, 3))    \n",
    "x = Flatten()(input_tensor)   \n",
    "\n",
    "x = Dense(1024, activation='relu')(x)    \n",
    "predictions = Dense(3, activation='softmax')(x)       \n",
    "model = Model(inputs=input_tensor, outputs=predictions)    \n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "39S0sdY8CP2b",
    "outputId": "5a05d6f6-744f-468e-fd4c-80a1dc61ae63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 794 images belonging to 3 classes.\n",
      "Found 156 images belonging to 3 classes.\n",
      "Found 279 images belonging to 3 classes.\n",
      "start history model\n"
     ]
    }
   ],
   "source": [
    "img_width,img_height=(224,224)\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator( rescale=1./255)#,\n",
    " #       shear_range=0.2,\n",
    " #       zoom_range=0.2,\n",
    " #       horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "print( \"start history model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p01aM7eeKki9"
   },
   "outputs": [],
   "source": [
    "setup_to_transfer_learning(model,base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1543
    },
    "colab_type": "code",
    "id": "PHQtQGKiCQDc",
    "outputId": "74d63c0f-18f8-4124-96b9-94b7fb92fe2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 9.2614 - acc: 0.4193 - val_loss: 9.6880 - val_acc: 0.3989\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 9.3464 - acc: 0.4201 - val_loss: 9.9452 - val_acc: 0.3830\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 9.3344 - acc: 0.4209 - val_loss: 9.0879 - val_acc: 0.4362\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 9.3524 - acc: 0.4198 - val_loss: 10.3739 - val_acc: 0.3564\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 9.3404 - acc: 0.4205 - val_loss: 9.4606 - val_acc: 0.4130\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 9.3284 - acc: 0.4212 - val_loss: 9.8595 - val_acc: 0.3883\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 9.3225 - acc: 0.4216 - val_loss: 10.0309 - val_acc: 0.3777\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 9.3344 - acc: 0.4209 - val_loss: 9.6880 - val_acc: 0.3989\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 9.3344 - acc: 0.4209 - val_loss: 9.3451 - val_acc: 0.4202\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 9.3524 - acc: 0.4198 - val_loss: 9.6358 - val_acc: 0.4022\n",
      "Epoch 11/50\n",
      " 89/100 [=========================>....] - ETA: 3s - loss: 9.3743 - acc: 0.4184"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-ea77ed5097f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     )\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_v1/car_res_tl.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_tl_2 = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=100,#\n",
    "                    epochs=50,#2\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=12,#12\n",
    "                    class_weight='auto'\n",
    "                    )\n",
    "model.save('data_v1/car_res_tl.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4MoTzs8CQP0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oH3ukGQCQa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddvauQHOCQm0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOvjoh3v-P7k"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "TKv22T3QEihk",
    "outputId": "c5f4647e-b623-40d4-87eb-a6a4b757749e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model_2 = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized), i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers: layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model_2.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPNgmpin5IqH"
   },
   "outputs": [],
   "source": [
    "setup_to_transfer_learning(model_2,base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "id": "NyrGv38Nx0Qf",
    "outputId": "782f2692-f694-46a0-e3a8-195ec10cb219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 479s 599ms/step - loss: 0.0450 - acc: 0.9869 - val_loss: 13.7175 - val_acc: 0.1489\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 200s 251ms/step - loss: 0.0360 - acc: 0.9883 - val_loss: 13.7175 - val_acc: 0.1489\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0385 - acc: 0.9879 - val_loss: 14.0605 - val_acc: 0.1277\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0244 - acc: 0.9919 - val_loss: 13.8890 - val_acc: 0.1383\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0274 - acc: 0.9911 - val_loss: 13.8405 - val_acc: 0.1413\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 200s 249ms/step - loss: 0.0317 - acc: 0.9898 - val_loss: 13.9747 - val_acc: 0.1330\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0283 - acc: 0.9914 - val_loss: 13.7175 - val_acc: 0.1489\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 199s 248ms/step - loss: 0.0252 - acc: 0.9921 - val_loss: 13.8890 - val_acc: 0.1383\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 198s 248ms/step - loss: 0.0240 - acc: 0.9910 - val_loss: 13.8033 - val_acc: 0.1436\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 198s 248ms/step - loss: 0.0225 - acc: 0.9922 - val_loss: 13.8405 - val_acc: 0.1413\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0206 - acc: 0.9927 - val_loss: 13.8890 - val_acc: 0.1383\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 198s 247ms/step - loss: 0.0215 - acc: 0.9924 - val_loss: 13.7175 - val_acc: 0.1489\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 200s 250ms/step - loss: 0.0215 - acc: 0.9927 - val_loss: 13.7175 - val_acc: 0.1489\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0157 - acc: 0.9944 - val_loss: 13.9747 - val_acc: 0.1330\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 198s 247ms/step - loss: 0.0166 - acc: 0.9935 - val_loss: 13.9281 - val_acc: 0.1359\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 200s 250ms/step - loss: 0.0214 - acc: 0.9922 - val_loss: 13.8890 - val_acc: 0.1383\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0200 - acc: 0.9935 - val_loss: 13.7175 - val_acc: 0.1489\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0169 - acc: 0.9940 - val_loss: 13.8890 - val_acc: 0.1383\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 200s 250ms/step - loss: 0.0180 - acc: 0.9943 - val_loss: 13.9747 - val_acc: 0.1330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 199s 249ms/step - loss: 0.0185 - acc: 0.9936 - val_loss: 13.7529 - val_acc: 0.1467\n"
     ]
    }
   ],
   "source": [
    "history_tl_2 = model_2.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=800,#\n",
    "                    epochs=20,#2\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=12,#12\n",
    "                    class_weight='auto'\n",
    "                    )\n",
    "model_2.save('data_v1/car_res_tl.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9y-VIc6j5K08"
   },
   "outputs": [],
   "source": [
    " setup_to_fine_tune(model_2,base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "kr1PjhBZyC1N",
    "outputId": "228df217-772d-4380-852f-57616be34842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "800/800 [==============================] - 587s 733ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "800/800 [==============================] - 587s 734ms/step - loss: 0.0033 - acc: 0.9994 - val_loss: 10.2443 - val_acc: 0.1667\n"
     ]
    }
   ],
   "source": [
    "history_ft_2 = model_2.fit_generator(generator=train_generator,\n",
    "                                 steps_per_epoch=800,\n",
    "                                 epochs=2,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 validation_steps=1,\n",
    "                                 class_weight='auto'\n",
    "                                    )\n",
    "model_2.save('data_v1/car_res_ft.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zVjZs5kc1SKZ",
    "outputId": "e7a668e8-0b10-47cd-beb4-5bb17f7ab532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.0625\n"
     ]
    }
   ],
   "source": [
    "scoreSeg = model_2.evaluate_generator(test_generator, 400)\n",
    "print(\"Accuracy = \",scoreSeg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyxD8mbziShN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJM_4T8ONGgK"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdxQ-T6_Mi1q"
   },
   "outputs": [],
   "source": [
    "model_2.load_weights('data_v1/car_res_ft.h5')#调用训练好权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "k4bUYvVGx0ca",
    "outputId": "0e12ac87-eb3a-45c2-ef1b-34fbbc2872b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 8s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_2 = model_2.predict_generator(test_generator,279, verbose=1)#生成step个数据，下面是对应的标签\n",
    "\n",
    "predicted_class_indices_2 = np.argmax(pred_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "251PFtGUD8_K",
    "outputId": "078a7813-2ffe-42a3-b164-9f61669e9179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(predicted_class_indices_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(A1,list(predicted_class_indices_2), target_names=['good_car',  'scratch','other']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "541XKWxeNjQr"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpfoJbmSJ_6N"
   },
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "ew25rDd4Kdy7",
    "outputId": "08914cc6-81ef-4325-f5f2-40643612d765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "kS3iGkB4KDDF",
    "outputId": "bc0bd6ba-8ad6-4295-b53b-43dbefe8b0e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model_3 = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized), i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers: layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "from keras.optimizers import SGD\n",
    "model_3.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZW55cgJJuzDV"
   },
   "outputs": [],
   "source": [
    "setup_to_transfer_learning(model_3,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "H7HEeDSoMYC8",
    "outputId": "2263d159-62a2-40f3-c68f-869064372d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 377s 4s/step - loss: 0.0909 - acc: 0.9769 - val_loss: 0.7036 - val_acc: 0.7826\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 374s 4s/step - loss: 0.0840 - acc: 0.9825 - val_loss: 0.5377 - val_acc: 0.8138\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 339s 3s/step - loss: 0.0773 - acc: 0.9837 - val_loss: 0.6905 - val_acc: 0.8032\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 380s 4s/step - loss: 0.0779 - acc: 0.9837 - val_loss: 0.6622 - val_acc: 0.7713\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 349s 3s/step - loss: 0.0721 - acc: 0.9862 - val_loss: 0.6470 - val_acc: 0.7926\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 375s 4s/step - loss: 0.0712 - acc: 0.9881 - val_loss: 0.6704 - val_acc: 0.7935\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 374s 4s/step - loss: 0.0640 - acc: 0.9887 - val_loss: 0.6771 - val_acc: 0.7872\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 394s 4s/step - loss: 0.0670 - acc: 0.9881 - val_loss: 0.6713 - val_acc: 0.7606\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 358s 4s/step - loss: 0.0639 - acc: 0.9896 - val_loss: 0.6065 - val_acc: 0.7926\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 346s 3s/step - loss: 0.0579 - acc: 0.9906 - val_loss: 0.7020 - val_acc: 0.7979\n"
     ]
    }
   ],
   "source": [
    "history_tl_3 = model_3.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=100,#\n",
    "                    epochs=10,#2\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=12,#12\n",
    "                    class_weight='auto'\n",
    "                    )\n",
    "model_3.save('data_v1/car_vgg_tl.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1345
    },
    "colab_type": "code",
    "id": "xf6xLbMdCAId",
    "outputId": "9fb4265b-0536-4a53-af04-399cbb5f90a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 375s 4s/step - loss: 0.0657 - acc: 0.9881 - val_loss: 3.6511 - val_acc: 0.3750\n",
      "Epoch 2/10\n",
      " 12/100 [==>...........................] - ETA: 5:49 - loss: 0.0636 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-9009b81a798f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                  \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                  class_weight='auto')\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0121/car_res_ft.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "setup_to_fine_tune(model_3,base_model)\n",
    "history_ft_3 = model_2.fit_generator(generator=train_generator,\n",
    "                                 steps_per_epoch=100,\n",
    "                                 epochs=10,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 validation_steps=1,\n",
    "                                 class_weight='auto')\n",
    "model_3.save('0121/car_res_ft.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Nj778vmNCKbJ",
    "outputId": "960236d2-8d25-4bcd-8862-6890f1fccc44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8810061271470887\n"
     ]
    }
   ],
   "source": [
    "scoreSeg = model_3.evaluate_generator(test_generator, 400)\n",
    "print(\"Accuracy = \",scoreSeg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jODmngqLCPJU"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rXuTJUEiDQ5h",
    "outputId": "5353d8f3-a38d-442b-a5a1-3185785a8e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 23s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_3 = model_3.predict_generator(test_generator,279, verbose=1)#生成step个数据，下面是对应的标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTfDlbNeDMe_"
   },
   "outputs": [],
   "source": [
    "\n",
    "predicted_class_indices_3 = np.argmax(pred_3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "pc6BqDsrCUSf",
    "outputId": "21c4d66b-d8b2-44a0-8561-c8bc2dc0d06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    good_car       0.99      0.92      0.95       112\n",
      "     scratch       0.50      0.64      0.56        25\n",
      "       other       0.89      0.89      0.89       142\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       279\n",
      "   macro avg       0.79      0.82      0.80       279\n",
      "weighted avg       0.89      0.88      0.89       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(A1,list(predicted_class_indices_3), target_names=['good_car',  'scratch','other']))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOSBPkvHLrTA"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3uvYgeOLuPr"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogNid35sfXRw"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBiUtjTDijfc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqFP6MSIijoy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2vmBigPijyZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxknsomXLxtF"
   },
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3))) \n",
    "#当使用该层作为第一层时，应提供input_shape参数。例如input_shape = (128,128,3)代表128*128的彩色RGB图像\n",
    "#32: filter的个数为32个\n",
    "#kernel_size: 卷积核的宽度和长度\n",
    "\n",
    "model_4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#为空域信号施加最大值池化\n",
    "#pool_size：长为2的整数tuple，代表在两个方向（竖直，水平）上的下采样因子，如取（2，2）将使图片在两个维度上均变为原长的一半\n",
    "\n",
    "model_4.add(BatchNormalization())\n",
    "#该层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1\n",
    "\n",
    "model_4.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "#32: filter的个数为64个\n",
    "model_4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "model_4.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model_4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "model_4.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model_4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "model_4.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model_4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "model_4.add(Dropout(0.2)) #为输入数据施加Dropout。Dropout将在训练过程中每次更新参数时随机断开一定百分比（p）的输入神经元连接，Dropout层用于防止过拟合。\n",
    "model_4.add(Flatten()) #Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。\n",
    "model_4.add(Dense(256, activation='relu')) #全连接层\n",
    "#units为256：大于0的整数，代表该层的输出维度。\n",
    "\n",
    "model_4.add(Dropout(0.2))\n",
    "model_4.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model_4.add(Dense(3, activation = 'softmax')) #最后一层，分类\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#编译\n",
    "model_4.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001, momentum=0.9), metrics = ['accuracy'])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17pWtOOVvNHP"
   },
   "outputs": [],
   "source": [
    "setup_to_transfer_learning(model_4,model_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6205
    },
    "colab_type": "code",
    "id": "sFC6ls37Lssl",
    "outputId": "9bc76373-fa6e-46db-d78a-238100a4830a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 1.4735 - acc: 0.2957 - val_loss: 1.1188 - val_acc: 0.1489\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11882, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 1.4806 - acc: 0.2728 - val_loss: 1.1216 - val_acc: 0.1170\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.11882\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 1.5076 - acc: 0.2794 - val_loss: 1.1182 - val_acc: 0.1489\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.11882 to 1.11815, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 1.4816 - acc: 0.2879 - val_loss: 1.1180 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.11815 to 1.11804, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 1.5073 - acc: 0.2744 - val_loss: 1.1187 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.11804\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 1.4867 - acc: 0.2806 - val_loss: 1.1178 - val_acc: 0.1543\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.11804 to 1.11777, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 1.4988 - acc: 0.2645 - val_loss: 1.1210 - val_acc: 0.1223\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.11777\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.5078 - acc: 0.2696 - val_loss: 1.1198 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.11777\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 1.4844 - acc: 0.2868 - val_loss: 1.1183 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.11777\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 1.4927 - acc: 0.2799 - val_loss: 1.1215 - val_acc: 0.1170\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.11777\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.4851 - acc: 0.2824 - val_loss: 1.1184 - val_acc: 0.1596\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.11777\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 1.4797 - acc: 0.2816 - val_loss: 1.1208 - val_acc: 0.1277\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.11777\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 1.4874 - acc: 0.2793 - val_loss: 1.1166 - val_acc: 0.1543\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.11777 to 1.11661, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 1.4896 - acc: 0.2838 - val_loss: 1.1183 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.11661\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.4879 - acc: 0.2768 - val_loss: 1.1202 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.11661\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 1.5267 - acc: 0.2688 - val_loss: 1.1197 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.11661\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 1.5107 - acc: 0.2724 - val_loss: 1.1188 - val_acc: 0.1489\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.11661\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.4740 - acc: 0.2796 - val_loss: 1.1168 - val_acc: 0.1543\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.11661\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.5080 - acc: 0.2909 - val_loss: 1.1202 - val_acc: 0.1359\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.11661\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 1.4973 - acc: 0.2774 - val_loss: 1.1189 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.11661\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.5002 - acc: 0.2747 - val_loss: 1.1179 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.11661\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.4819 - acc: 0.2846 - val_loss: 1.1202 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.11661\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.4954 - acc: 0.2947 - val_loss: 1.1207 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.11661\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.4507 - acc: 0.3048 - val_loss: 1.1180 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.11661\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 1.5064 - acc: 0.2741 - val_loss: 1.1185 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.11661\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 1.4534 - acc: 0.3024 - val_loss: 1.1217 - val_acc: 0.1170\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.11661\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 1.5039 - acc: 0.2853 - val_loss: 1.1170 - val_acc: 0.1543\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.11661\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.4959 - acc: 0.2875 - val_loss: 1.1204 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.11661\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 1.4829 - acc: 0.2810 - val_loss: 1.1181 - val_acc: 0.1576\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.11661\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.4891 - acc: 0.2790 - val_loss: 1.1201 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.11661\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 1.4814 - acc: 0.2897 - val_loss: 1.1170 - val_acc: 0.1596\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.11661\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 1.5048 - acc: 0.2796 - val_loss: 1.1195 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.11661\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.5410 - acc: 0.2624 - val_loss: 1.1186 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.11661\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 1.4745 - acc: 0.2804 - val_loss: 1.1205 - val_acc: 0.1359\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.11661\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 1.4934 - acc: 0.2794 - val_loss: 1.1207 - val_acc: 0.1277\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.11661\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.4911 - acc: 0.2763 - val_loss: 1.1166 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.11661 to 1.11657, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.5049 - acc: 0.2949 - val_loss: 1.1192 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.11657\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.4900 - acc: 0.2856 - val_loss: 1.1190 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.11657\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.5012 - acc: 0.2843 - val_loss: 1.1201 - val_acc: 0.1359\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.11657\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 1.5192 - acc: 0.2721 - val_loss: 1.1202 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.11657\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5070 - acc: 0.2689 - val_loss: 1.1168 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.11657\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 1.4926 - acc: 0.2866 - val_loss: 1.1214 - val_acc: 0.1277\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.11657\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 1.4942 - acc: 0.2744 - val_loss: 1.1168 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.11657\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.4811 - acc: 0.2914 - val_loss: 1.1206 - val_acc: 0.1359\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.11657\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 1.4922 - acc: 0.2631 - val_loss: 1.1192 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.11657\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 1.4757 - acc: 0.2766 - val_loss: 1.1195 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.11657\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 1.4770 - acc: 0.2876 - val_loss: 1.1216 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.11657\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.4752 - acc: 0.2774 - val_loss: 1.1148 - val_acc: 0.1596\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.11657 to 1.11476, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 1.5069 - acc: 0.2729 - val_loss: 1.1207 - val_acc: 0.1304\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.11476\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 1.5021 - acc: 0.2936 - val_loss: 1.1179 - val_acc: 0.1489\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.11476\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 1.5255 - acc: 0.2614 - val_loss: 1.1227 - val_acc: 0.1223\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.11476\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 1.4883 - acc: 0.2861 - val_loss: 1.1139 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.11476 to 1.11390, saving model to data_v1/0122_baseline_best_weights.hdf5\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 1.5296 - acc: 0.2710 - val_loss: 1.1245 - val_acc: 0.1117\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.11390\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 1.4989 - acc: 0.2656 - val_loss: 1.1166 - val_acc: 0.1576\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.11390\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 1.5248 - acc: 0.2709 - val_loss: 1.1189 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.11390\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.4647 - acc: 0.2870 - val_loss: 1.1202 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.11390\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.4987 - acc: 0.2771 - val_loss: 1.1176 - val_acc: 0.1543\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.11390\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 1.5001 - acc: 0.2740 - val_loss: 1.1187 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.11390\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 1.5290 - acc: 0.2772 - val_loss: 1.1203 - val_acc: 0.1359\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.11390\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 1.4670 - acc: 0.2824 - val_loss: 1.1201 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.11390\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 1.4740 - acc: 0.2967 - val_loss: 1.1171 - val_acc: 0.1543\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.11390\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 1.4812 - acc: 0.2771 - val_loss: 1.1201 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.11390\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 1.4801 - acc: 0.3085 - val_loss: 1.1192 - val_acc: 0.1489\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.11390\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 1.4968 - acc: 0.2781 - val_loss: 1.1193 - val_acc: 0.1304\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.11390\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 1.5049 - acc: 0.2702 - val_loss: 1.1190 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.11390\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 1.4966 - acc: 0.2701 - val_loss: 1.1199 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.11390\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.4918 - acc: 0.2791 - val_loss: 1.1197 - val_acc: 0.1330\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.11390\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.5219 - acc: 0.2836 - val_loss: 1.1178 - val_acc: 0.1543\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.11390\n",
      "Epoch 69/100\n",
      " 23/100 [=====>........................] - ETA: 21s - loss: 1.4159 - acc: 0.3505"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-df8e2180384c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                     )\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_v1/car_cnn_tl.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath = 'data_v1/0122_baseline_best_weights.hdf5',verbose=1\n",
    "                              ,save_best_only =True)\n",
    "history_tl_4 = model_4.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=100,#800\n",
    "                    epochs=100,#2\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=12,#12\n",
    "                    callbacks=[checkpointer]\n",
    "                    )\n",
    "model_4.save('data_v1/car_cnn_tl.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1327
    },
    "colab_type": "code",
    "id": "rXAIPbCx7f0s",
    "outputId": "4ec0d90a-5d42-4018-fabd-ebd0e31fd653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 1.9009 - acc: 0.2062 - val_loss: 1.1172 - val_acc: 0.0938\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 1.8826 - acc: 0.2087 - val_loss: 1.1041 - val_acc: 0.1875\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.8820 - acc: 0.2044 - val_loss: 1.1101 - val_acc: 0.1562\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 1.8934 - acc: 0.2108 - val_loss: 1.1219 - val_acc: 0.1250\n",
      "Epoch 5/50\n",
      " 79/200 [==========>...................] - ETA: 25s - loss: 1.9045 - acc: 0.2231"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-d539d352b52b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                  \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                  class_weight='auto')\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0121/car_cnn_fh.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "setup_to_fine_tune(model_4,base_model)\n",
    "history_ft_4 = model_4.fit_generator(generator=train_generator,\n",
    "                                 steps_per_epoch=200,\n",
    "                                 epochs=50,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 validation_steps=2,\n",
    "                                 class_weight='auto')\n",
    "model_4.save('0121/car_cnn_fh.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZZV8tOJBEOH"
   },
   "outputs": [],
   "source": [
    "scoreSeg = model_4.evaluate_generator(test_generator, 400)\n",
    "print(\"Accuracy = \",scoreSeg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mfS7z5WBF4c"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred_4 = model_4.predict_generator(test_generator,280, verbose=1)#生成step个数据，下面是对应的标签\n",
    "\n",
    "predicted_class_indices_4 = np.argmax(pred_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxNBqxpWBP45"
   },
   "outputs": [],
   "source": [
    "print(classification_report(A1,list(predicted_class_indices_4), target_names=['good_car',  'scratch','other']))  \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet3.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
